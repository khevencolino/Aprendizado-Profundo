---
title: Autoencoders para Fashion-MNIST
sub_title: CompressÃ£o e Denoising de Imagens usando Deep Learning
author: Kheven
date: 2025
options:
  end_slide_shorthand: true
theme:
  name: gruvbox-dark
---

# Autoencoders para Fashion-MNIST

## CompressÃ£o e Denoising de Imagens usando Deep Learning

---

## Objetivo

ğŸ¯ **Implementar dois tipos de Autoencoders para processamento de imagens**

- **Autoencoder Convolucional**: CompressÃ£o e reconstruÃ§Ã£o de imagens
- **Denoising Autoencoder**: RemoÃ§Ã£o de ruÃ­do gaussiano
- **Dataset**: Fashion-MNIST (70.000 imagens de roupas/acessÃ³rios)
- **Framework**: Keras

---

## O que sÃ£o Autoencoders?

ğŸ§  **Arquitetura de rede neural nÃ£o-supervisionada**

```
Input â†’ [Encoder] â†’ Latent Space â†’ [Decoder] â†’ Output
28Ã—28    Compress     4Ã—4Ã—128      Reconstruct  28Ã—28
```

### CaracterÃ­sticas:

- **Encoder**: Comprime dados para representaÃ§Ã£o latente
- **Decoder**: ReconstrÃ³i dados a partir da representaÃ§Ã£o comprimida
- **Objetivo**: Input â‰ˆ Output (reconstruÃ§Ã£o fiel)
- **AplicaÃ§Ãµes**: CompressÃ£o, denoising, geraÃ§Ã£o de dados

---

## Dataset Fashion-MNIST

ğŸ“Š **CaracterÃ­sticas dos dados:**

- **70.000 imagens**: 60.000 treino + 10.000 teste
- **ResoluÃ§Ã£o**: 28Ã—28 pixels (escala de cinza)
- **10 classes**: T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot

```python
# Carregamento e normalizaÃ§Ã£o
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
x_train = x_train.astype('float32') / 255.0  # NormalizaÃ§Ã£o [0,1]
x_test = x_test.astype('float32') / 255.0

# Redimensionar para CNNs
x_train_reshaped = x_train.reshape(x_train.shape[0], 28, 28, 1)
```

---

## VisualizaÃ§Ã£o dos Dados

![image:width:80%](output.png)

**Classes representadas:**

- Roupas: T-shirt, Pullover, Dress, Coat, Shirt
- CalÃ§ados: Sandal, Sneaker, Ankle boot
- AcessÃ³rios: Bag
- CalÃ§as: Trouser

---

## Autoencoder Convolucional - Arquitetura

ğŸ—ï¸ **Estrutura hierÃ¡rquica com convoluÃ§Ãµes:**

### Encoder (CompressÃ£o):

```python
# Encoder - Downsampling gradual
Conv2D(32, (3,3), relu) + MaxPooling2D(2,2)    # 28Ã—28 â†’ 14Ã—14
Conv2D(64, (3,3), relu) + MaxPooling2D(2,2)    # 14Ã—14 â†’ 7Ã—7
Conv2D(128, (3,3), relu) + MaxPooling2D(2,2)   # 7Ã—7 â†’ 4Ã—4Ã—128
```

### Decoder (ReconstruÃ§Ã£o):

```python
# Decoder - Upsampling gradual
Conv2D(128, (3,3), relu) + UpSampling2D(2,2)   # 4Ã—4 â†’ 8Ã—8
Conv2D(64, (3,3), relu) + UpSampling2D(2,2)    # 8Ã—8 â†’ 16Ã—16
Conv2D(32, (3,3), relu) + UpSampling2D(2,2)    # 16Ã—16 â†’ 32Ã—32
Conv2D(1, (3,3), sigmoid)                      # 32Ã—32 â†’ 28Ã—28
```

**Taxa de compressÃ£o**: 784 pixels â†’ 2.048 valores â†’ 784 pixels

---

## Treinamento do Autoencoder

âš™ï¸ **ConfiguraÃ§Ã£o do treinamento:**

```python
# CompilaÃ§Ã£o
autoencoder_conv.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Callbacks para otimizaÃ§Ã£o
early_stopping = EarlyStopping(monitor='val_loss', patience=10)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)

# Treinamento (Input = Output para autoencoder)
history = autoencoder_conv.fit(
    x_train_reshaped, x_train_reshaped,  # Entrada = SaÃ­da desejada
    epochs=50, batch_size=128,
    validation_data=(x_test_reshaped, x_test_reshaped),
    callbacks=[early_stopping, reduce_lr]
)
```

---

## Curvas de Treinamento - Autoencoder

![image:width:80%](output2.png)

ğŸ“ˆ **AnÃ¡lise do treinamento:**

- ConvergÃªncia estÃ¡vel do MSE e MAE
- Sem overfitting significativo
- Early stopping otimizou nÃºmero de Ã©pocas

---

## Resultados - Autoencoder BÃ¡sico

![image:width:80%](output3.png)

ğŸ“Š **MÃ©tricas de performance:**

- **MSE mÃ©dio**: ~0.005-0.010
- **Qualidade visual**: Boa preservaÃ§Ã£o de detalhes principais
- **CompressÃ£o**: 784 â†’ 2.048 â†’ 784 (3.9x compressÃ£o espacial)

---

## Denoising Autoencoder - Conceito

ğŸ”§ **ExtensÃ£o para remoÃ§Ã£o de ruÃ­do:**

### Processo:

1. **Adicionar ruÃ­do gaussiano** Ã s imagens originais
2. **Treinar** modelo para reconstruir versÃ£o limpa
3. **Input**: Imagem com ruÃ­do
4. **Output**: Imagem original (sem ruÃ­do)

```python
def add_noise(images, noise_factor=0.3):
    noise = np.random.normal(loc=0.0, scale=1.0, size=images.shape)
    noisy_images = images + noise_factor * noise
    return np.clip(noisy_images, 0.0, 1.0)

x_train_noisy = add_noise(x_train_reshaped, 0.3)
```

---

## VisualizaÃ§Ã£o do RuÃ­do

![image:width:80%](output4.png)

**CaracterÃ­sticas do ruÃ­do:**

- **Tipo**: Gaussiano com mÃ©dia 0
- **Intensidade**: Factor 0.3
- **DistribuiÃ§Ã£o**: Uniforme em toda a imagem

---

## Denoising Autoencoder - Arquitetura

ğŸ—ï¸ **Arquitetura aprimorada com regularizaÃ§Ã£o:**

```python
# Encoder robusto com Dropout
Conv2D(32, (3,3), relu) + MaxPooling2D(2,2)      # 28Ã—28 â†’ 14Ã—14
Conv2D(64, (3,3), relu) + MaxPooling2D(2,2)      # 14Ã—14 â†’ 7Ã—7
Conv2D(128, (3,3), relu) + Dropout(0.25) + MaxPooling2D(2,2)  # 7Ã—7 â†’ 4Ã—4

# Decoder com regularizaÃ§Ã£o
Conv2D(128, (3,3), relu) + Dropout(0.25) + UpSampling2D(2,2)  # 4Ã—4 â†’ 8Ã—8
Conv2D(64, (3,3), relu) + UpSampling2D(2,2)      # 8Ã—8 â†’ 16Ã—16
Conv2D(32, (3,3), relu) + UpSampling2D(2,2)      # 16Ã—16 â†’ 32Ã—32
Conv2D(1, (3,3), sigmoid)                        # 32Ã—32 â†’ 28Ã—28
```

**Novidade**: Dropout para melhor generalizaÃ§Ã£o contra ruÃ­do

---

## Treinamento do Denoising Autoencoder

âš™ï¸ **ConfiguraÃ§Ã£o especÃ­fica para denoising:**

```python
# Treinamento: Entrada com ruÃ­do â†’ SaÃ­da limpa
history_denoising = denoising_autoencoder_conv.fit(
    x_train_noisy_2d, x_train_reshaped,    # Input: ruÃ­do, Output: limpo
    epochs=60, batch_size=128,
    validation_data=(x_test_noisy_2d, x_test_reshaped),
    callbacks=[early_stopping, reduce_lr]
)
```

**DiferenÃ§a crucial**: Input â‰  Output (imagem ruidosa â†’ imagem limpa)

---

## Curvas de Treinamento - Denoising

![image:width:80%](output5.png)

ğŸ“ˆ **ObservaÃ§Ãµes:**

- ConvergÃªncia mais lenta devido Ã  complexidade da tarefa
- Maior nÃºmero de Ã©pocas necessÃ¡rias
- Dropout ajudou na regularizaÃ§Ã£o

---

## Resultados - Denoising Autoencoder

![image:width:80%](output6.png)

ğŸ“Š **MÃ©tricas de performance:**

- **MSE (ruÃ­do vs original)**: ~0.090
- **MSE (denoised vs original)**: ~0.015
- **Melhoria relativa**: ~83% de reduÃ§Ã£o do erro
- **Qualidade visual**: Excelente remoÃ§Ã£o de ruÃ­do

---

## ComparaÃ§Ã£o dos Modelos

ğŸ“Š **MÃ©tricas comparativas:**

| Modelo                    | MSE em Imagens Limpas | ParÃ¢metros | Especialidade    |
| ------------------------- | --------------------- | ---------- | ---------------- |
| **Autoencoder BÃ¡sico**    | 0.005-0.010           | ~160K      | CompressÃ£o       |
| **Denoising Autoencoder** | 0.010-0.015           | ~165K      | RemoÃ§Ã£o de ruÃ­do |

### Vantagens das ConvoluÃ§Ãµes:

- âœ… **PreservaÃ§Ã£o espacial** da estrutura das imagens
- âœ… **Upsampling/Downsampling gradual** preserva detalhes

---

## ComparaÃ§Ã£o Visual Final

![image:width:80%](output7.png)

**AnÃ¡lise qualitativa:**

- **Autoencoder bÃ¡sico**: Excelente para imagens limpas
- **Denoising autoencoder**: Superior em cenÃ¡rios ruidosos
- **Ambos**: MantÃªm caracterÃ­sticas essenciais das roupas

---

## Detalhes TÃ©cnicos

ğŸ”§ **EspecificaÃ§Ãµes importantes:**

### CompressÃ£o:

- **Entrada**: 28Ã—28Ã—1 = 784 pixels
- **Bottleneck**: 4Ã—4Ã—128 = 2.048 valores
- **Taxa de compressÃ£o**: 2.6x menor representaÃ§Ã£o

### Arquitetura:

- **Tipo**: Encoder-Decoder convolucional
- **FunÃ§Ãµes de ativaÃ§Ã£o**: ReLU (hidden), Sigmoid (output)
- **Loss function**: Mean Squared Error (MSE)
- **Otimizador**: Adam

---

## Principais Aprendizados

ğŸ“ **Insights tÃ©cnicos:**

### Arquitetura:

- **ConvoluÃ§Ãµes** sÃ£o superiores a MLPs para imagens
- **Downsampling/Upsampling gradual** preserva informaÃ§Ã£o
- **Dropout** melhora robustez contra ruÃ­do

### Treinamento:

- **Early stopping** previne overfitting
- **Learning rate scheduling** melhora convergÃªncia
- **MSE** Ã© adequado para reconstruÃ§Ã£o de imagens

### Performance:

- **Denoising** requer mais Ã©pocas que autoencoding bÃ¡sico
- **Trade-off** entre compressÃ£o e qualidade de reconstruÃ§Ã£o

---

## ConclusÃµes

âœ… **Objetivos alcanÃ§ados:**

- ğŸ¯ **Autoencoders implementados** com sucesso
- ğŸ“ˆ **CompressÃ£o eficaz** mantendo qualidade visual
- ğŸ”§ **Denoising robusto** com 83% de melhoria
- ğŸ—ï¸ **Arquiteturas convolucionais** otimizadas

---

# Obrigado!

ğŸš€ **PrÃ³ximo projeto:** AnÃ¡lise de Sentimentos com LSTM

---
