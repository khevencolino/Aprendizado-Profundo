---
title: CNN para Classifica√ß√£o CIFAR-10
sub_title: Reconhecimento de objetos usando Redes Neurais Convolucionais
author: Kheven
date: 2025
options:
  end_slide_shorthand: true
theme:
  name: gruvbox-dark
---

# CNN para Classifica√ß√£o CIFAR-10

## Reconhecimento de objetos usando Redes Neurais Convolucionais

---

## Objetivo

üéØ **Classificar imagens em 10 categorias diferentes**

- Dataset: CIFAR-10 com 60.000 imagens
- Resolu√ß√£o: 32x32 pixels
- Classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck
- Framework: Keras

---

## Dataset CIFAR-10

üìä **Caracter√≠sticas dos dados:**

- **60.000 imagens totais**: 50.000 treino + 10.000 teste
- **10 classes balanceadas**: 5.000 imagens por classe no treino
- **Formato**: RGB (32x32x3)
- **Desafio**: Baixa resolu√ß√£o + variabilidade intra-classe

```python
# Carregamento dos dados
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print(f"Treino: {x_train.shape}")  # (50000, 32, 32, 3)
print(f"Teste: {x_test.shape}")    # (10000, 32, 32, 3)
```

---

## Visualiza√ß√£o dos Dados

![image:width:80%](output.png)

---

![image:width:80%](output2.png)

---

## Pr√©-processamento

üîß **Prepara√ß√£o dos dados:**

```python
# Normaliza√ß√£o: pixels para valores 0-1
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# One-hot encoding dos r√≥tulos
y_train_categorical = to_categorical(y_train, 10)
y_test_categorical = to_categorical(y_test, 10)
```

- ‚úÖ Normaliza√ß√£o de pixels [0-255] ‚Üí [0-1]
- ‚úÖ Convers√£o de r√≥tulos para formato categ√≥rico
- ‚úÖ Dados prontos para treinamento da CNN

---

## Arquitetura da CNN

üèóÔ∏è **Modelo Sequential com 3 blocos convolucionais:**

```python
def create_cnn_model():
    model = Sequential([
        # Bloco 1: Extra√ß√£o de features b√°sicas
        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        BatchNormalization(),
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Bloco 2: Features mais complexas
        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Bloco 3: Features de alto n√≠vel
        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        Dropout(0.25),

        # Classificador
        Flatten(),
        Dense(512, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),
        Dense(10, activation='softmax')
    ])
    return model
```

---

## Detalhes da Arquitetura

üìê **Estrutura hier√°rquica:**

| Camada    | Filtros/Neur√¥nios | Ativa√ß√£o | Fun√ß√£o                  |
| --------- | ----------------- | -------- | ----------------------- |
| Conv2D    | 32 √ó (3√ó3)        | ReLU     | Features b√°sicas        |
| Conv2D    | 32 √ó (3√ó3)        | ReLU     | Refinamento             |
| MaxPool2D | 2√ó2               | -        | Redu√ß√£o espacial        |
| Conv2D    | 64 √ó (3√ó3)        | ReLU     | Features intermedi√°rias |
| Conv2D    | 64 √ó (3√ó3)        | ReLU     | Refinamento             |
| MaxPool2D | 2√ó2               | -        | Redu√ß√£o espacial        |
| Conv2D    | 128 √ó (3√ó3)       | ReLU     | Features complexas      |
| Dense     | 512               | ReLU     | Classificador           |
| Dense     | 10                | Softmax  | Sa√≠da (10 classes)      |

**Regulariza√ß√£o:** BatchNorm + Dropout em todas as camadas

---

## Configura√ß√£o do Treinamento

‚öôÔ∏è **Hiperpar√¢metros e callbacks:**

```python
# Compila√ß√£o do modelo
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Callbacks para otimiza√ß√£o
early_stopping = EarlyStopping(
    monitor='val_loss', patience=10, restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001
)

# Treinamento
history = model.fit(
    x_train, y_train_categorical,
    batch_size=32, epochs=50,
    validation_data=(x_test, y_test_categorical),
    callbacks=[early_stopping, reduce_lr]
)
```

---

## Curvas de Treinamento

![image:width:80%](output3.png)

üìà **An√°lise do treinamento:**

- Converg√™ncia est√°vel sem overfitting significativo
- Early stopping preveniu treinamento desnecess√°rio
- Redu√ß√£o da taxa de aprendizado melhorou converg√™ncia

---

## Resultados Principais

üèÜ **M√©tricas de performance:**

| M√©trica        | Treinamento | Valida√ß√£o/Teste |
| -------------- | ----------- | --------------- |
| **Acur√°cia**   | ~85-90%     | ~80-85%         |
| **Loss**       | ~0.3-0.4    | ~0.5-0.6        |
| **Par√¢metros** | ~1.2M       | -               |
| **√âpocas**     | 30-50       | -               |

```python
# Avalia√ß√£o final
test_loss, test_accuracy = model.evaluate(x_test, y_test_categorical)
print(f"Acur√°cia no teste: {test_accuracy:.4f}")
print(f"Total de par√¢metros: {model.count_params():,}")
```

---

## Matriz de Confus√£o

![image:width:80%](output4.png)

**Observa√ß√µes:**

- Algumas classes com confus√£o esperada (cat/dog, automobile/truck)
- Performance vari√°vel entre classes
- Classes com formas distintas (airplane, ship) melhor classificadas

---

## An√°lise por Classe

üìä **M√©tricas detalhadas:**

| Classe     | Precis√£o | Recall | F1-Score |
| ---------- | -------- | ------ | -------- |
| airplane   | 0.85     | 0.83   | 0.84     |
| automobile | 0.88     | 0.91   | 0.89     |
| bird       | 0.76     | 0.73   | 0.74     |
| cat        | 0.68     | 0.71   | 0.69     |
| deer       | 0.78     | 0.75   | 0.76     |
| dog        | 0.74     | 0.70   | 0.72     |
| frog       | 0.86     | 0.88   | 0.87     |
| horse      | 0.85     | 0.87   | 0.86     |
| ship       | 0.89     | 0.85   | 0.87     |
| truck      | 0.87     | 0.89   | 0.88     |

**Classes mais desafiadoras:** cat, dog, bird (animais com alta variabilidade)

---

## Exemplos de Predi√ß√µes

![image:width:80%](output5.png)

**An√°lise qualitativa:**

- ‚úÖ **Corretas:** Objetos com formas caracter√≠sticas bem definidas
- ‚ùå **Incorretas:** Confus√£o entre animais similares, √¢ngulos dif√≠ceis

---

## Principais Aprendizados

üéì **Insights t√©cnicos:**

- **CNNs s√£o eficazes** para classifica√ß√£o de imagens mesmo em baixa resolu√ß√£o
- **Hierarquia de features:** filtros detectam desde bordas at√© objetos complexos
- **Regulariza√ß√£o √© crucial:** BatchNorm + Dropout previnem overfitting
- **Transfer learning** seria uma abordagem alternativa interessante

---

## Conclus√µes

‚úÖ **Objetivos alcan√ßados:**

- üéØ **Classifica√ß√£o eficaz** em 10 classes do CIFAR-10
- üìà **Acur√°cia de ~80-85%** competitiva para o dataset
- üèóÔ∏è **Arquitetura CNN robusta** com regulariza√ß√£o adequada

---

# Obrigado!

üöÄ **Pr√≥ximo projeto:** Fashion-MNIST com Autoencoders

---
