---
title: PrediÃ§Ã£o de SobrevivÃªncia no Titanic
sub_title: ClassificaÃ§Ã£o BinÃ¡ria com MLP
author: Kheven
date: 2025
options:
  end_slide_shorthand: true
theme:
  name: catppuccin-latte
---

# PrediÃ§Ã£o de SobrevivÃªncia no Titanic

## ClassificaÃ§Ã£o BinÃ¡ria com MLP

---

## Objetivo

**Prever a sobrevivÃªncia de passageiros do Titanic usando redes neurais**

- **Problema**: ClassificaÃ§Ã£o binÃ¡ria (sobreviveu/nÃ£o sobreviveu)
- **Dataset**: Dados histÃ³ricos de passageiros
- **Arquitetura**: MLP com regularizaÃ§Ã£o
- **Framework**: Keras

---

## O Desastre do Titanic

**Contexto histÃ³rico:**

### O que aconteceu:

- **14 de abril de 1912**: NaufrÃ¡gio do RMS Titanic
- **2.224 pessoas** a bordo
- **1.514 mortes** - uma das maiores tragÃ©dias marÃ­timas
- **"Mulheres e crianÃ§as primeiro"** - protocolo de evacuaÃ§Ã£o

### Por que Ã© importante para ML:

- **Dados reais** com impacto humano
- **PadrÃµes sociais** claros nos dados
- **Desbalanceamento** representa situaÃ§Ãµes reais

---

## Dataset e AnÃ¡lise ExploratÃ³ria

**CaracterÃ­sticas dos dados:**

- **891 passageiros** no conjunto de treino
- **418 passageiros** no conjunto de teste
- **Taxa de sobrevivÃªncia**: 38.4% (desbalanceado)
- **12 features** originais + engenharia de caracterÃ­sticas

```python
# Carregamento dos dados
train_df = pd.read_csv('DATA/train.csv')
test_df = pd.read_csv('DATA/test.csv')

print(f"Taxa de SobrevivÃªncia: {train_df['Survived'].mean():.2%}")
```

### Principais variÃ¡veis:

- **Pclass**: Classe do bilhete (1Âª, 2Âª, 3Âª classe)
- **Sex**: Sexo do passageiro
- **Age**: Idade
- **Fare**: Tarifa paga
- **Embarked**: Porto de embarque

---

## AnÃ¡lise de Valores Ausentes

**Tratamento de dados faltantes:**

| VariÃ¡vel     | Valores Ausentes | EstratÃ©gia                 |
| ------------ | ---------------- | -------------------------- |
| **Age**      | 177 (19.9%)      | Preenchimento com mediana  |
| **Embarked** | 2 (0.2%)         | Preenchimento com moda     |
| **Cabin**    | 687 (77.1%)      | Removida (muitos ausentes) |
| **Fare**     | 1 (teste)        | Preenchimento com mediana  |

```python
# Tratamento de valores ausentes
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
```

**EstratÃ©gia conservadora**: Evitar introduzir viÃ©s com imputaÃ§Ãµes complexas.

---

## VisualizaÃ§Ãµes ExploratÃ³rias

![](output.png)

- _DistribuiÃ§Ã£o de sobrevivÃªncia (pizza)_
- _SobrevivÃªncia por sexo (barras)_
- _SobrevivÃªncia por classe (barras)_
- _DistribuiÃ§Ã£o de idade (histograma)_
- _SobrevivÃªncia por porto de embarque_
- _DistribuiÃ§Ã£o de tarifa_

**Insights visuais:**

- **Mulheres** tiveram taxa de sobrevivÃªncia muito maior
- **1Âª classe** sobreviveu mais que 2Âª e 3Âª classes
- **CrianÃ§as** tiveram maior chance de sobrevivÃªncia
- **Porto de embarque** influenciou na sobrevivÃªncia

---

## AnÃ¡lise de CorrelaÃ§Ã£o

![](output2.png)

**CorrelaÃ§Ãµes principais com sobrevivÃªncia:**

| VariÃ¡vel        | CorrelaÃ§Ã£o | InterpretaÃ§Ã£o                         |
| --------------- | ---------- | ------------------------------------- |
| **Sex_encoded** | -0.543     | Ser homem diminui chances             |
| **Pclass**      | -0.338     | Classes mais altas sobrevivem mais    |
| **Fare**        | +0.257     | Tarifas maiores = maior sobrevivÃªncia |
| **Age**         | -0.077     | Idade mais avanÃ§ada = menor chance    |

```python
# AnÃ¡lise de correlaÃ§Ã£o
correlation_df = temp_df[numeric_cols].corr()
target_correlation = correlation_df['Survived'].sort_values(key=abs, ascending=False)
```

---

## Feature Engineering

**CriaÃ§Ã£o de novas variÃ¡veis:**

### 1. Tamanho da FamÃ­lia:

```python
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
df['IsAlone'] = (df['FamilySize'] == 1).astype(int)

# CategorizaÃ§Ã£o
df['FamilySize_Category'] = 'Medium'
df.loc[df['FamilySize'] == 1, 'FamilySize_Category'] = 'Single'
df.loc[df['FamilySize'] >= 5, 'FamilySize_Category'] = 'Large'
```

### 2. Grupos de Idade:

```python
df['AgeGroup'] = 'Adult'
df.loc[df['Age'] <= 16, 'AgeGroup'] = 'Child'
df.loc[df['Age'] >= 60, 'AgeGroup'] = 'Elderly'
```

### 3. Faixas de Tarifa:

```python
df['FareGroup'] = pd.qcut(df['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'])
```

---

## CodificaÃ§Ã£o de VariÃ¡veis

**TransformaÃ§Ã£o categÃ³rica â†’ numÃ©rica:**

```python
def encode_categorical_variables(train_df, test_df):
    categorical_cols = ['Sex', 'Embarked', 'FamilySize_Category',
                       'AgeGroup', 'FareGroup']

    # One-Hot Encoding
    train_encoded = pd.get_dummies(train_df, columns=categorical_cols)
    test_encoded = pd.get_dummies(test_df, columns=categorical_cols)

    # Garantir mesmas colunas em treino e teste
    return train_encoded, test_encoded
```

### Resultado:

- **10 features** finais apÃ³s codificaÃ§Ã£o
- **ConsistÃªncia** entre treino e teste
- **Escalabilidade** para novos dados

---

## NormalizaÃ§Ã£o dos Dados

**PadronizaÃ§Ã£o para redes neurais:**

```python
# SeparaÃ§Ã£o e normalizaÃ§Ã£o
X = train_encoded.drop('Survived', axis=1)
y = train_encoded['Survived']

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
```

**Por que normalizar?**

- **Diferentes escalas**: Idade (0-80) vs IsAlone (0-1)
- **ConvergÃªncia mais rÃ¡pida** do gradiente
- **Estabilidade numÃ©rica** da rede neural

---

## Arquitetura do Modelo MLP

**Rede neural com regularizaÃ§Ã£o:**

```python
model = Sequential([
    Input(shape=(10,)),                    # 10 features de entrada
    Dense(64, activation='relu'),          # Camada oculta 1
    Dropout(0.3),                         # RegularizaÃ§Ã£o
    Dense(32, activation='relu'),          # Camada oculta 2
    Dense(1, activation='sigmoid')         # SaÃ­da binÃ¡ria
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
```

### EspecificaÃ§Ãµes:

- **2.817 parÃ¢metros** treinÃ¡veis
- **ReLU** para camadas ocultas
- **Sigmoid** para probabilidade de sobrevivÃªncia
- **Dropout** para prevenir overfitting

---

## ConfiguraÃ§Ã£o do Treinamento

**Callbacks inteligentes:**

```python
# Callbacks para otimizaÃ§Ã£o automÃ¡tica
early_stopping = EarlyStopping(
    monitor='val_loss', patience=20, restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001
)

# Treinamento
history = model.fit(
    X_train_scaled, y_train,
    epochs=200, batch_size=32,
    validation_data=(X_val_scaled, y_val),
    callbacks=[early_stopping, reduce_lr]
)
```

### BenefÃ­cios:

- **Early stopping**: Evita overfitting
- **Learning rate reduction**: Melhora convergÃªncia
- **RestauraÃ§Ã£o de pesos**: Usa melhor modelo

---

## Curvas de Treinamento

![image:width:80%](output3.png)

**AnÃ¡lise do treinamento:**

- **ConvergÃªncia estÃ¡vel** sem oscilaÃ§Ãµes bruscas
- **Sem overfitting significativo** (gap treino-validaÃ§Ã£o pequeno)
- **30-50 Ã©pocas** tÃ­picas antes do early stopping
- **Learning rate reduction** melhorou convergÃªncia final

**EstatÃ­sticas tÃ­picas:**

- Loss final: ~0.44
- Accuracy final: ~82%
- Melhor Ã©poca: 31
- Early stopping ativado

---

## Resultados Principais

**MÃ©tricas de performance:**

| MÃ©trica      | Valor | InterpretaÃ§Ã£o                  |
| ------------ | ----- | ------------------------------ |
| **Accuracy** | 82.1% | Boa classificaÃ§Ã£o geral        |
| **PrecisÃ£o** | 0.82  | Poucos falsos positivos        |
| **Recall**   | 0.78  | Detecta bem sobreviventes      |
| **F1-Score** | 0.80  | Balanceamento precision/recall |

```python
# AvaliaÃ§Ã£o final
test_accuracy = accuracy_score(y_val, y_val_pred)
precision = precision_score(y_val, y_val_pred)
recall = recall_score(y_val, y_val_pred)
f1 = f1_score(y_val, y_val_pred)
```

---

## Matriz de ConfusÃ£o

![image:width:80%](output4.png)

**AnÃ¡lise dos erros:**

- **Verdadeiros Negativos**: Modelo acerta nÃ£o-sobreviventes
- **Falsos Positivos**: PrevÃª sobrevivÃªncia incorretamente
- **Falsos Negativos**: NÃ£o detecta sobreviventes
- **Verdadeiros Positivos**: Acerta sobreviventes

### MÃ©tricas detalhadas:

- **Sensibilidade**: Capacidade de detectar sobreviventes
- **Especificidade**: Capacidade de detectar nÃ£o-sobreviventes
- **PrecisÃ£o por classe**: Confiabilidade das prediÃ§Ãµes

---

## AnÃ¡lise de Probabilidades

![image:width:80%](output5.png)

ðŸ“Š **DistribuiÃ§Ã£o das prediÃ§Ãµes:**

- **DistribuiÃ§Ã£o bimodal**: Maioria prÃ³xima a 0 ou 1
- **ConfianÃ§a alta**: Modelo Ã© "decidido" na maioria dos casos
- **Threshold 0.5**: Ponto de corte bem definido

```python
# AnÃ¡lise das probabilidades
y_pred_proba = model.predict(X_val_scaled)
print(f"Probabilidade mÃ©dia: {y_pred_proba.mean():.3f}")
print(f"Desvio padrÃ£o: {y_pred_proba.std():.3f}")
```

---

## ImportÃ¢ncia das Features

![image:width:70%](output6.png)

**Features mais determinantes:**

| Rank | Feature        | ImportÃ¢ncia | InterpretaÃ§Ã£o                          |
| ---- | -------------- | ----------- | -------------------------------------- |
| 1    | **Pclass**     | 0.122       | Classe social Ã© crucial                |
| 2    | **Sex_female** | 0.102       | Sexo feminino aumenta muito as chances |
| 3    | **SibSp**      | 0.040       | NÃºmero de irmÃ£os/cÃ´njuges              |
| 4    | **Age**        | 0.039       | Idade influencia sobrevivÃªncia         |
| 5    | **Sex_male**   | 0.037       | Ser homem diminui as chances           |

```python
# CÃ¡lculo da importÃ¢ncia
perm_importance = permutation_importance(
    model, X_val_scaled, y_val, n_repeats=5, random_state=42
)
```

---

## PrediÃ§Ãµes no Conjunto de Teste

**Resultados finais:**

```python
# PrediÃ§Ãµes finais
test_predictions = (model.predict(X_test_scaled) > 0.5).astype(int)
survival_rate_predicted = sum(test_predictions) / len(test_predictions)

print(f"Total de passageiros: {len(test_predictions)}")
print(f"Sobreviventes preditos: {sum(test_predictions)}")
print(f"Taxa de sobrevivÃªncia predita: {survival_rate_predicted:.1%}")
```

### ComparaÃ§Ã£o histÃ³rica:

- **Taxa original**: 38.4%
- **Taxa predita**: 39.7%
- **Alinhamento**: Excelente (diferenÃ§a de apenas 1.3%)

---

## Principais Aprendizados

**Insights tÃ©cnicos:**

### Sobre RegularizaÃ§Ã£o:

- **Dropout** foi essencial para evitar overfitting
- **Early stopping** otimizou automaticamente o treinamento
- **Learning rate scheduling** melhorou convergÃªncia

### Sobre os Dados:

- **Pclass** foi o fator mais determinante
- **Sexo** teve impacto forte na sobrevivÃªncia
- **SibSp** (irmÃ£os/cÃ´njuges) tambÃ©m influenciou significativamente
- **Protocolo "mulheres e crianÃ§as primeiro"** Ã© visÃ­vel nos dados

---

## LimitaÃ§Ãµes e Desafios

**Pontos de atenÃ§Ã£o:**

### LimitaÃ§Ãµes dos dados:

- **Amostra pequena**: 891 exemplos para treino
- **Valores ausentes**: 20% da idade estava faltando

### Desafios do modelo:

- **Desbalanceamento**: 38% vs 62% de sobreviventes
- **Interpretabilidade**: MLP Ã© menos interpretÃ¡vel que Ã¡rvores
- **Overfitting**: Risco com poucos dados

### ConsideraÃ§Ãµes Ã©ticas:

- **ViÃ©s histÃ³rico**: Modelo reflete desigualdades de 1912

---

# Obrigado!

## **PrÃ³ximo projeto:** CNN para ClassificaÃ§Ã£o CIFAR-10
